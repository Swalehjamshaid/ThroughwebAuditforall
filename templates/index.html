# fftech_elite_audit.py
import asyncio
import requests
from bs4 import BeautifulSoup
from playwright.async_api import async_playwright
from fpdf import FPDF
import re
from urllib.parse import urlparse

# ------------------------
# Helper Functions
# ------------------------
def normalize_url(url: str) -> str:
    if not url.startswith("http"):
        url = "https://" + url
    return url

def check_https(url):
    return urlparse(url).scheme == "https"

def fetch_html(url):
    try:
        r = requests.get(url, timeout=15)
        return r.text, r.status_code, r.headers
    except:
        return "", 0, {}

def check_meta_tags(soup, tag_name):
    tag = soup.find(tag_name)
    if tag and tag.get("content"):
        return True, tag.get("content")
    return False, ""

def check_h_tags(soup, tag="h1"):
    tags = soup.find_all(tag)
    return len(tags), [t.get_text(strip=True) for t in tags]

def check_robots_txt(url):
    try:
        r = requests.get(url.rstrip('/') + "/robots.txt", timeout=10)
        return r.status_code == 200
    except:
        return False

def check_sitemap(url):
    try:
        r = requests.get(url.rstrip('/') + "/sitemap.xml", timeout=10)
        return r.status_code == 200
    except:
        return False

def analyze_images(soup):
    imgs = soup.find_all("img")
    alt_missing = sum(1 for i in imgs if not i.get("alt"))
    return len(imgs), alt_missing

def security_headers(headers):
    results = {
        "HSTS": "strict-transport-security" in headers,
        "CSP": "content-security-policy" in headers,
        "X-Frame-Options": "x-frame-options" in headers,
        "X-XSS-Protection": "x-xss-protection" in headers,
        "X-Content-Type-Options": "x-content-type-options" in headers,
        "Referrer-Policy": "referrer-policy" in headers,
    }
    return results

# ------------------------
# Core Web Vitals / Performance
# ------------------------
async def get_performance_metrics(url, device="desktop"):
    async with async_playwright() as p:
        browser = await p.chromium.launch()
        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080} if device=="desktop" else {"width": 375, "height": 812}
        )
        page = await context.new_page()
        try:
            await page.goto(url, wait_until="networkidle")
            perf = await page.evaluate("""() => JSON.stringify(window.performance.timing)""")
            metrics = eval(perf)
            # Simplified calculations for example
            fcp = metrics['responseStart'] - metrics['navigationStart']
            ttfb = metrics['responseStart'] - metrics['requestStart']
            dom_load = metrics['domContentLoadedEventEnd'] - metrics['navigationStart']
            return {
                "FCP": min(int(fcp/10),100),
                "TTFB": min(int(ttfb/10),100),
                "DOM Load": min(int(dom_load/10),100)
            }
        except:
            return {"FCP":0, "TTFB":0, "DOM Load":0}
        finally:
            await browser.close()

# ------------------------
# Full Audit Function
# ------------------------
async def full_audit(url, device="desktop"):
    url = normalize_url(url)
    html, status_code, headers = fetch_html(url)
    soup = BeautifulSoup(html, "html.parser")

    metrics = []

    # --- SEO Checks ---
    # Title
    title_present = bool(soup.title)
    title_text = soup.title.string if title_present else ""
    metrics.append({"name":"Title Present","category":"SEO","score":100 if title_present else 0})
    metrics.append({"name":"Title Length","category":"SEO","score":min(len(title_text), 60)})

    # Meta Description
    desc_present, desc_text = check_meta_tags(soup,"meta",)
    metrics.append({"name":"Meta Description Present","category":"SEO","score":100 if desc_present else 0})
    metrics.append({"name":"Meta Description Length","category":"SEO","score":min(len(desc_text),160)})

    # H1 Tags
    h1_count, h1_texts = check_h_tags(soup,"h1")
    metrics.append({"name":"H1 Tags Count","category":"SEO","score":100 if h1_count==1 else max(0,100-abs(h1_count-1)*50)})

    # Robots.txt & Sitemap
    metrics.append({"name":"Robots.txt","category":"SEO","score":100 if check_robots_txt(url) else 0})
    metrics.append({"name":"Sitemap.xml","category":"SEO","score":100 if check_sitemap(url) else 0})

    # Image alt tags
    total_imgs, missing_alt = analyze_images(soup)
    score = 100 if total_imgs==0 else max(0, int((total_imgs-missing_alt)/total_imgs*100))
    metrics.append({"name":"Images with alt text","category":"SEO","score":score})

    # --- Security Checks ---
    sec_headers = security_headers(headers)
    for h, v in sec_headers.items():
        metrics.append({"name":h,"category":"Security","score":100 if v else 0})

    metrics.append({"name":"HTTPS Enabled","category":"Security","score":100 if check_https(url) else 0})

    # --- UX Checks (simplified) ---
    # Mobile friendly: check viewport
    viewport = soup.find("meta", attrs={"name":"viewport"})
    metrics.append({"name":"Viewport Meta","category":"UX","score":100 if viewport else 0})

    # --- Core Web Vitals / Performance ---
    perf_metrics = await get_performance_metrics(url, device)
    for k,v in perf_metrics.items():
        metrics.append({"name":k,"category":"Performance","score":v})

    # --- Aggregate Scores ---
    pillars = {
        "Performance": int(sum(m["score"] for m in metrics if m["category"]=="Performance")/max(1,len([m for m in metrics if m["category"]=="Performance"]))),
        "SEO": int(sum(m["score"] for m in metrics if m["category"]=="SEO")/max(1,len([m for m in metrics if m["category"]=="SEO"]))),
        "UX": int(sum(m["score"] for m in metrics if m["category"]=="UX")/max(1,len([m for m in metrics if m["category"]=="UX"]))),
        "Security": int(sum(m["score"] for m in metrics if m["category"]=="Security")/max(1,len([m for m in metrics if m["category"]=="Security"]))),
    }

    total_grade = int(sum(pillars.values())/4)

    summary = "Website audit completed successfully."

    return {
        "url": url,
        "total_grade": total_grade,
        "summary": summary,
        "pillars": pillars,
        "metrics": metrics
    }

# ------------------------
# PDF Generation
# ------------------------
def generate_pdf(audit_data, filename="audit_report.pdf"):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", "B", 16)
    pdf.cell(0, 10, f"Website Audit Report: {audit_data['url']}", ln=True)
    pdf.ln(5)
    pdf.set_font("Arial","",12)
    pdf.cell(0,10,f"Total Score: {audit_data['total_grade']}%", ln=True)
    pdf.ln(10)

    for pillar, score in audit_data['pillars'].items():
        pdf.cell(0,10,f"{pillar}: {score}%", ln=True)
    pdf.ln(10)

    for m in audit_data['metrics']:
        pdf.cell(0,8,f"{m['category']} - {m['name']}: {m['score']}%", ln=True)

    pdf.output(filename)

# ------------------------
# Run Example
# ------------------------
if __name__ == "__main__":
    url_to_test = "https://example.com"
    data = asyncio.run(full_audit(url_to_test))
    print(data)
    generate_pdf(data, "audit_example.pdf")
